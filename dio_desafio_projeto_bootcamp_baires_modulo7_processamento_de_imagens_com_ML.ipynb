{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ETAPA 1 - Baixar biblioteca de extração, baixar e organizar dataset - 4 classes\n",
        "!pip install icrawler"
      ],
      "metadata": {
        "id": "B-K7lR6014w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Baixar Dataset de imagens\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "import os\n",
        "\n",
        "# Defina suas classes com a palavra-chave ajustada para notebooks\n",
        "classes = ['laptop', 'bola de futebol', 'smart tv', 'violao']\n",
        "\n",
        "# Diretório base para salvar as imagens\n",
        "base_dir = './images'\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "for class_name in classes:\n",
        "    print(f\"Coletando imagens para a classe: {class_name}\")\n",
        "\n",
        "    # Crie uma pasta para a classe. O nome da pasta será 'laptop'\n",
        "    # para evitar espaços e manter a consistência.\n",
        "    class_dir = os.path.join(base_dir, class_name.replace(' ', '_'))\n",
        "    if not os.path.exists(class_dir):\n",
        "        os.makedirs(class_dir)\n",
        "\n",
        "    # Configura o rastreador de imagens do Google\n",
        "    google_crawler = GoogleImageCrawler(\n",
        "        feeder_threads=1,\n",
        "        parser_threads=1,\n",
        "        downloader_threads=4,\n",
        "        storage={'root_dir': class_dir}\n",
        "    )\n",
        "\n",
        "    # Inicia a coleta de imagens\n",
        "    google_crawler.crawl(\n",
        "        keyword=class_name,\n",
        "        max_num=500,\n",
        "        min_size=(200, 200)\n",
        "    )\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"Coleta de imagens concluída!\")\n",
        "print(f\"As imagens foram salvas em: {base_dir}\")"
      ],
      "metadata": {
        "id": "fZ7Dbl8-eqoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ETAPA 2 - Encodificando as imagens\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "id": "FNQQ4lWaiBKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODULE_HANDLE = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "IMAGE_SIZE = (224, 224)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "BATCH_SIZE = 32\n",
        "N_FEATURES = 256"
      ],
      "metadata": {
        "id": "SmfhqznfiIbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "data_dir = '/content/images'"
      ],
      "metadata": {
        "id": "r7raGWgRiLs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "metadata": {
        "id": "4P_blrhHiQwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.layers import Layer\n",
        "from keras.saving import register_keras_serializable\n",
        "\n",
        "# 1. Registre sua classe personalizada para que ela possa ser salva e carregada\n",
        "@register_keras_serializable()\n",
        "class HubLayerWrapper(Layer):\n",
        "    def __init__(self, module_handle, trainable=False, **kwargs):\n",
        "        super(HubLayerWrapper, self).__init__(**kwargs)\n",
        "        self.module_handle = module_handle\n",
        "        self.hub_layer = hub.KerasLayer(module_handle, trainable=trainable)\n",
        "        self.hub_layer.trainable = trainable\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        return self.hub_layer(inputs, training=training)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(HubLayerWrapper, self).get_config()\n",
        "        config.update({\n",
        "            'module_handle': self.module_handle,\n",
        "            'trainable': self.hub_layer.trainable,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# 2. Use a nova classe para construir o modelo completo\n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "# Definir a camada de entrada\n",
        "inputs = tf.keras.layers.Input(shape=IMAGE_SIZE + (3,))\n",
        "\n",
        "# Conectar a camada do TensorFlow Hub usando sua nova classe\n",
        "hub_layer = HubLayerWrapper(MODULE_HANDLE, trainable=False)(inputs)\n",
        "\n",
        "# Adicionar a primeira camada Dropout\n",
        "dropout_1 = tf.keras.layers.Dropout(rate=0.2)(hub_layer)\n",
        "\n",
        "# Adicionar a primeira camada Dense\n",
        "dense_1 = tf.keras.layers.Dense(\n",
        "    N_FEATURES, kernel_regularizer=tf.keras.regularizers.l2(0.0001)\n",
        ")(dropout_1)\n",
        "\n",
        "# Adicionar a segunda camada Dropout\n",
        "dropout_2 = tf.keras.layers.Dropout(rate=0.2)(dense_1)\n",
        "\n",
        "# Adicionar a camada de saída\n",
        "outputs = tf.keras.layers.Dense(\n",
        "    train_generator.num_classes, kernel_regularizer=tf.keras.regularizers.l2(0.0001)\n",
        ")(dropout_2)\n",
        "\n",
        "# Construir o modelo completo com a API Funcional\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "# E também o seu extrator de características\n",
        "feature_extractor = tf.keras.Model(inputs=inputs, outputs=dense_1)"
      ],
      "metadata": {
        "id": "JF6YOGYiiVMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimiser and loss\n",
        "lr = 0.003 * BATCH_SIZE / 512\n",
        "SCHEDULE_LENGTH = 500\n",
        "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
        "\n",
        "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
        "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES,\n",
        "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9DavhNMEiYjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history"
      ],
      "metadata": {
        "id": "5gUKzkWsib9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])"
      ],
      "metadata": {
        "id": "ZT41ZNxpifj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Crie um diretório para salvar os modelos\n",
        "caminho_local = '/content/modelos_salvos/'\n",
        "if not os.path.exists(caminho_local):\n",
        "    os.mkdir(caminho_local)\n",
        "\n",
        "# Salve o extrator de características\n",
        "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
        "feature_extractor.save(caminho_local + 'bit_feature_extractor.keras')\n",
        "\n",
        "# Salve o modelo completo\n",
        "saved_model_path = caminho_local + 'bit_model'\n",
        "model.save(saved_model_path + '.keras')"
      ],
      "metadata": {
        "id": "zTNiRgIJimWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ETAPA 3 - VETORIZAÇÃO DE IMAGEM\n",
        "\n",
        "#hide\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "TJ0OtR6yjdb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "img_paths = []\n",
        "extensions = ['*.jpg', '*.png']\n",
        "\n",
        "for ext in extensions:\n",
        "    for path in Path('/content/images').rglob(ext):\n",
        "        img_paths.append(path)\n",
        "\n",
        "np.random.shuffle(img_paths)"
      ],
      "metadata": {
        "id": "ts6WQsBNju0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(path):\n",
        "    # Lê o arquivo de imagem\n",
        "    img = tf.io.read_file(path)\n",
        "\n",
        "    # Decodifica a imagem automaticamente (JPEG, PNG, etc.)\n",
        "    # A decodificação sem o argumento 'channels' preserva o formato original\n",
        "    img = tf.io.decode_image(img, channels=3)\n",
        "\n",
        "    # Redimensiona a imagem com preenchimento para as dimensões do modelo\n",
        "    img = tf.image.resize_with_pad(img, 224, 224)\n",
        "\n",
        "    # Converte o tipo de dados da imagem e adiciona uma dimensão para o lote (batch)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "Mz190zRyj_E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide-output\n",
        "TRANSFER_LEARNING_FLAG = 1\n",
        "if TRANSFER_LEARNING_FLAG:\n",
        "  module = tf.keras.models.load_model('/content/modelos_salvos/bit_feature_extractor.keras', safe_mode=False)\n",
        "else:\n",
        "  module_handle = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "  module = hub.load(module_handle)"
      ],
      "metadata": {
        "id": "LgnM7OMIkJ_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgvec_path = '/content/img_vectors/'\n",
        "Path(imgvec_path).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "CMsxeyGlk6An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in tqdm(img_paths[:5000]):\n",
        "    try:\n",
        "        # Tenta carregar a imagem\n",
        "        img = load_img(str(filename))\n",
        "\n",
        "        # Processa a imagem se o carregamento for bem-sucedido\n",
        "        features = module(img)\n",
        "        feature_set = np.squeeze(features)\n",
        "\n",
        "        # Salva o vetor de características\n",
        "        outfile_name = os.path.basename(filename).split('.')[0] + \".npz\"\n",
        "        out_path_file = os.path.join(imgvec_path, outfile_name)\n",
        "        np.savetxt(out_path_file, feature_set, delimiter=',')\n",
        "\n",
        "    except Exception as e:\n",
        "        # Se ocorrer um erro, imprime uma mensagem e continua para o próximo arquivo\n",
        "        print(f\"Erro ao processar o arquivo {filename}: {e}\")\n",
        "        continue"
      ],
      "metadata": {
        "id": "wPRMtUWPlMMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METADADOS E INDEXAÇÃO\n",
        "\n",
        "#hide\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "!pip install -q annoy\n",
        "import json\n",
        "from annoy import AnnoyIndex\n",
        "from scipy import spatial\n",
        "import pickle\n",
        "from IPython.display import Image as dispImage"
      ],
      "metadata": {
        "id": "v0qWkfeQlNCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = '/content/images/violao/000001.jpg'\n",
        "dispImage(test_img)"
      ],
      "metadata": {
        "id": "_zD3oP_6lWC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Crie os dicionários que farão o mapeamento do índice do vetor para os nomes dos arquivos\n",
        "file_index_to_file_name = {}\n",
        "file_index_to_product_id = {}\n",
        "\n",
        "# Localiza todas as imagens (JPG e PNG) nas subpastas\n",
        "all_images = glob.glob('/content/images/*/*.jpg') + glob.glob('/content/images/*/*.png')\n",
        "\n",
        "for i, path in enumerate(all_images):\n",
        "  file_name = Path(path).name\n",
        "  file_index_to_file_name[i] = file_name\n",
        "  # Extrai a categoria do nome da pasta pai (ex: 'laptop', 'violao')\n",
        "  category = Path(path).parts[-2]\n",
        "  file_index_to_product_id[i] = category\n",
        "\n",
        "# Nota: O dicionário file_index_to_file_vector será preenchido mais tarde\n",
        "\n",
        "# Exemplo de verificação para ver quantas imagens foram encontradas\n",
        "print(f\"Total de imagens encontradas: {len(all_images)}\")"
      ],
      "metadata": {
        "id": "ZAo24lcVlvib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_id(fname):\n",
        "  return styles.index[styles.id==fname].values[0]"
      ],
      "metadata": {
        "id": "9fdabVX8lzaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining data structures as empty dict\n",
        "file_index_to_file_name = {}\n",
        "file_index_to_file_vector = {}\n",
        "file_index_to_product_id = {}\n",
        "\n",
        "# Configuring annoy parameters\n",
        "dims = 256\n",
        "n_nearest_neighbors = 20\n",
        "trees = 10000\n",
        "\n",
        "# Reads all file names which stores feature vectors\n",
        "allfiles = glob.glob('/content/img_vectors/*.npz')\n",
        "\n",
        "t = AnnoyIndex(dims, metric='angular')"
      ],
      "metadata": {
        "id": "voOnSut2l2R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for findex, fname in tqdm(enumerate(allfiles)):\n",
        "  file_vector = np.loadtxt(fname)\n",
        "  file_name = os.path.basename(fname)\n",
        "  file_index_to_file_name[findex] = file_name\n",
        "  file_index_to_file_vector[findex] = file_vector\n",
        "\n",
        "  # Extraia a categoria da pasta pai\n",
        "  category = Path(fname).parts[-2]\n",
        "  file_index_to_product_id[findex] = category\n",
        "\n",
        "  t.add_item(findex, file_vector)"
      ],
      "metadata": {
        "id": "QjEemBnjl5NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide-output\n",
        "t.build(trees)\n",
        "t.save('t.ann')"
      ],
      "metadata": {
        "id": "MqTWu008l8JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Defina o caminho para a pasta de índices dentro do Colab\n",
        "file_path = '/content/indices_salvos/'\n",
        "\n",
        "# Crie a pasta se ela não existir\n",
        "if not os.path.exists(file_path):\n",
        "    os.mkdir(file_path)"
      ],
      "metadata": {
        "id": "nB49s5aol-tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.save(file_path+'indexer.ann')\n",
        "pickle.dump(file_index_to_file_name, open(file_path+\"file_index_to_file_name.p\", \"wb\"))\n",
        "pickle.dump(file_index_to_file_vector, open(file_path+\"file_index_to_file_vector.p\", \"wb\"))\n",
        "pickle.dump(file_index_to_product_id, open(file_path+\"file_index_to_product_id.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "ksMVnogKmW-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Etapa 5 - TESTE LOCAL\n",
        "#hide\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "_SpMJWzemdCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Use uma nova URL de imagem mais confiável\n",
        "img_addr = 'https://upload.wikimedia.org/wikipedia/commons/e/e5/Viol%C3%B3_el%C3%A8ctric.jpg'\n",
        "\n",
        "# Baixe a imagem e verifique se o download foi bem-sucedido\n",
        "!wget -q -O img.jpg $img_addr\n",
        "test_img = 'img.jpg'\n",
        "\n",
        "if os.path.getsize(test_img) > 0:\n",
        "    print(\"Download da imagem concluído com sucesso!\")\n",
        "    topK = 4\n",
        "\n",
        "    # Processamento da imagem\n",
        "    test_vec = np.squeeze(module(load_img(test_img), training=False))\n",
        "\n",
        "    basewidth = 224\n",
        "    img = Image.open(test_img)\n",
        "    wpercent = (basewidth/float(img.size[0]))\n",
        "    hsize = int((float(img.size[1])*float(wpercent)))\n",
        "\n",
        "    # Redimensione a imagem com a sintaxe correta\n",
        "    img = img.resize((basewidth,hsize), Image.Resampling.LANCZOS)\n",
        "    img\n",
        "else:\n",
        "    print(\"Erro: O download da imagem falhou ou o arquivo está vazio.\")"
      ],
      "metadata": {
        "id": "3qPUC12UmoKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ETAPA 6 - CHAMADA DE API\n",
        "#hide\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "ae4mO87DnjsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Defina a pasta raiz do seu projeto\n",
        "root_path = '/content/projeto_salvo'\n",
        "\n",
        "# Crie a pasta se ela ainda não existir\n",
        "Path(root_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# O restante do seu código pode vir aqui\n",
        "# As próximas linhas que você for executar devem usar o root_path para salvar e carregar arquivos"
      ],
      "metadata": {
        "id": "VX7JTpYynq62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "### ----utils.py---- ###\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "root_path = '/content/projeto_salvo'\n",
        "\n",
        "class Encoder:\n",
        "  encoder = tf.keras.models.load_model(os.path.join(root_path, 'bit_feature_extractor.keras'), safe_mode=False)\n",
        "\n",
        "class Indexer:\n",
        "  dims = 256\n",
        "  topK = 6\n",
        "  indexer = AnnoyIndex(dims, 'angular')\n",
        "  indexer.load(os.path.join(root_path, 'indexer.ann'))\n",
        "\n",
        "encoder = Encoder()\n",
        "indexer = Indexer()"
      ],
      "metadata": {
        "id": "90ZtIWlkoFAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "!pip install streamlit\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from annoy import AnnoyIndex\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import time\n",
        "from utils import encoder, indexer\n",
        "\n",
        "# Define variables for the app\n",
        "root_path = '/content/projeto_salvo'\n",
        "topK = 6\n",
        "query_path = '/content/user_query.jpg'\n",
        "\n",
        "# Load the model and indexer from the utils.py file\n",
        "try:\n",
        "    start_time = time.time()\n",
        "    encoder = encoder.encoder\n",
        "    print(\"---Encoder--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    t = indexer.indexer\n",
        "    print(\"---Indexer--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading model or indexer: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# Load the mappings\n",
        "try:\n",
        "    file_index_to_file_name = pickle.load(open(os.path.join(root_path ,'file_index_to_file_name.p'), 'rb'))\n",
        "    file_index_to_product_id = pickle.load(open(os.path.join(root_path ,'file_index_to_product_id.p'), 'rb'))\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading mappings: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# Load and prepare the image paths\n",
        "path_dict = {}\n",
        "all_images = glob.glob(os.path.join(root_path, 'images', '*', '*.jpg')) + glob.glob(os.path.join(root_path, 'images', '*', '*.png'))\n",
        "for file_path in all_images:\n",
        "    file_name = Path(file_path).name\n",
        "    path_dict[file_name] = file_path\n",
        "\n",
        "def load_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=3)\n",
        "    img = tf.image.resize_with_pad(img, 224, 224)\n",
        "    img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    return img\n",
        "\n",
        "st.title(\"Image Similarity App\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    image.save(query_path)\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Top similar images...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    test_vec = np.squeeze(encoder(load_img(query_path), training=False))\n",
        "    st.write(\"---Encoding--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    nns = t.get_nns_by_vector(test_vec, n=topK)\n",
        "    st.write(\"---SimilarityIndex--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    img_files = []\n",
        "    img_captions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in nns:\n",
        "        # Get the file name from the index\n",
        "        img_name = file_index_to_file_name[i]\n",
        "\n",
        "        # Use path_dict to get the full path\n",
        "        if img_name in path_dict:\n",
        "            img_path = path_dict[img_name]\n",
        "\n",
        "            try:\n",
        "                img_file = Image.open(img_path)\n",
        "                img_files.append(img_file)\n",
        "                # Use the product ID from the index to create a caption\n",
        "                caption = file_index_to_product_id[i]\n",
        "                img_captions.append(caption)\n",
        "            except FileNotFoundError:\n",
        "                st.warning(f\"Image not found for index {i}: {img_name}\")\n",
        "\n",
        "    st.image(img_files, caption=img_captions, width=200)\n",
        "    st.write(\"---Output--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "0HGEjiNFoO9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from annoy import AnnoyIndex\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import time\n",
        "from utils import encoder, indexer\n",
        "\n",
        "# Defina o caminho para a sua pasta local\n",
        "root_path = '/content/projeto_salvo'\n",
        "topK = 6\n",
        "query_path = '/content/user_query.jpg'\n",
        "\n",
        "# Carrega o modelo e o indexador\n",
        "try:\n",
        "    start_time = time.time()\n",
        "    encoder = encoder.encoder\n",
        "    print(\"---Encoder--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    t = indexer.indexer\n",
        "    print(\"---Indexer--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"Erro ao carregar o modelo ou indexador: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# Carrega os mapeamentos\n",
        "try:\n",
        "    file_index_to_file_name = pickle.load(open(os.path.join(root_path ,'file_index_to_file_name.p'), 'rb'))\n",
        "    file_index_to_product_id = pickle.load(open(os.path.join(root_path ,'file_index_to_product_id.p'), 'rb'))\n",
        "except Exception as e:\n",
        "    st.error(f\"Erro ao carregar os mapeamentos: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# Prepara os caminhos das imagens\n",
        "path_dict = {}\n",
        "all_images = glob.glob(os.path.join(root_path, 'images', '*', '*.jpg')) + glob.glob(os.path.join(root_path, 'images', '*', '*.png'))\n",
        "for file_path in all_images:\n",
        "    file_name = Path(file_path).name\n",
        "    path_dict[file_name] = file_path\n",
        "\n",
        "def load_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=3)\n",
        "    img = tf.image.resize_with_pad(img, 224, 224)\n",
        "    img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    return img\n",
        "\n",
        "st.title(\"Image Similarity App\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    image.save(query_path)\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Top similar images...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    test_vec = np.squeeze(encoder(load_img(query_path), training=False))\n",
        "    st.write(\"---Encoding--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    nns = t.get_nns_by_vector(test_vec, n=topK)\n",
        "    st.write(\"---SimilarityIndex--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    img_files = []\n",
        "    img_captions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in nns:\n",
        "        # Pega o nome do arquivo do índice\n",
        "        img_name = file_index_to_file_name[i]\n",
        "\n",
        "        # Usa o path_dict para obter o caminho completo\n",
        "        if img_name in path_dict:\n",
        "            img_path = path_dict[img_name]\n",
        "\n",
        "            try:\n",
        "                img_file = Image.open(img_path)\n",
        "                img_files.append(img_file)\n",
        "                # Usa o ID do produto para criar uma legenda\n",
        "                caption = file_index_to_product_id[i]\n",
        "                img_captions.append(caption)\n",
        "            except FileNotFoundError:\n",
        "                st.warning(f\"Imagem não encontrada para o índice {i}: {img_name}\")\n",
        "\n",
        "    st.image(img_files, caption=img_captions, width=200)\n",
        "    st.write(\"---Output--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "KL6JYVCmCU6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala as bibliotecas necessárias para a sessão\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "\n",
        "# Importa a biblioteca para acessar os segredos do Colab\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Obtém o token de autenticação do ngrok de forma segura\n",
        "try:\n",
        "    NGROK_AUTH_TOKEN = userdata.get(\"NGROK_AUTH_TOKEN\")\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao obter o token ngrok. Verifique se ele está configurado nos Segredos do Colab: {e}\")\n",
        "\n",
        "# Fecha qualquer túnel ngrok que possa estar rodando\n",
        "ngrok.kill()\n",
        "\n",
        "# Inicia o túnel ngrok na porta 8501\n",
        "print(\"Iniciando o túnel ngrok...\")\n",
        "start_time = time.time()\n",
        "ngrok_tunnel = ngrok.connect(8501)\n",
        "print(\"---ngrok--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(\"Link para o seu aplicativo Streamlit:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Inicia a sua aplicação Streamlit\n",
        "!streamlit run app.py --server.headless=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO6RV1O2of7t",
        "outputId": "fe44ba4b-dabf-4a52-8e4f-e0323d75aaf1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function shutdown at 0x78058a437060>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 2259, in shutdown\n",
            "    h.acquire()\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 973, in acquire\n",
            "    self.lock.acquire()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/bootstrap.py\", line 43, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/server.py\", line 509, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/runtime.py\", line 329, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 844, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ]
    }
  ]
}